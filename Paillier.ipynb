{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homomorphic Encryption Experimentation with Paillier Encryption\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates an end-to-end experiment using the Paillier encryption scheme, which supports additive homomorphism. We simulate a simple linear model (dot-product plus bias) on various types of data:\n",
    "- **Tabular Data:** Diabetes dataset (regression)\n",
    "- **Image Data:** MNIST (flattened image)\n",
    "- **Text Data:** TF-IDF features from a subset of newsgroup articles (as a proxy for sentiment analysis)\n",
    "- **Time Series Data:** Simulated stock prices\n",
    "\n",
    "We then explore how varying key sizes (which affects security and performance) influences the encryption and decryption process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp39-cp39-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (8.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/ryan/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow) (3.21.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp39-cp39-macosx_12_0_arm64.whl (239.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp39-cp39-macosx_10_14_universal2.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp39-cp39-macosx_10_9_universal2.whl (396 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.3-cp38-abi3-macosx_10_9_universal2.whl (417 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp39-cp39-macosx_11_0_arm64.whl (327 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, grpcio, google-pasta, gast, astunparse, absl-py, markdown-it-py, markdown, tensorboard, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 keras-3.8.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 protobuf-5.29.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install phe\n",
    "# !pip install tensorflow\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For tabular and text data processing\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# For image data (MNIST)\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Import Paillier from the phe library\n",
    "from phe import paillier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paillier_keys(key_length=1024):\n",
    "    \"\"\"\n",
    "    Generate Paillier public and private keys.\n",
    "    \"\"\"\n",
    "    public_key, private_key = paillier.generate_paillier_keypair(n_length=key_length)\n",
    "    return public_key, private_key\n",
    "\n",
    "def encrypt_vector(vector, public_key):\n",
    "    \"\"\"\n",
    "    Encrypt a 1D numpy vector element-wise.\n",
    "    Returns a list of encrypted numbers.\n",
    "    \"\"\"\n",
    "    return [public_key.encrypt(float(x)) for x in vector]\n",
    "\n",
    "def encrypted_dot_product(enc_vector, weights):\n",
    "    \"\"\"\n",
    "    Compute the dot product between an encrypted vector (list of EncryptedNumber)\n",
    "    and a plaintext weight vector (numpy array or list). Multiplication by a plaintext constant is allowed.\n",
    "    \"\"\"\n",
    "    # Start with an encryption of zero (using the first encrypted element's public key)\n",
    "    public_key = enc_vector[0].public_key\n",
    "    enc_result = public_key.encrypt(0.0)\n",
    "    for enc_x, w in zip(enc_vector, weights):\n",
    "        enc_result += enc_x * float(w)\n",
    "    return enc_result\n",
    "\n",
    "def encrypted_linear_inference(enc_vector, weights, bias, public_key):\n",
    "    \"\"\"\n",
    "    Compute the encrypted linear inference: dot(enc_vector, weights) + bias.\n",
    "    The bias is added as a plaintext constant.\n",
    "    \"\"\"\n",
    "    enc_dot = encrypted_dot_product(enc_vector, weights)\n",
    "    # Adding the bias (plaintext) to the encrypted dot product.\n",
    "    return enc_dot + float(bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Tabular Data (Diabetes Dataset)\n",
    "\n",
    "We load the Diabetes dataset, standardize its features, choose one sample, and simulate a linear model inference on encrypted data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Diabetes Dataset (Tabular Data) ===\n",
      "Plaintext prediction: -0.1641\n",
      "Encrypted (decrypted) prediction: -0.1641\n"
     ]
    }
   ],
   "source": [
    "# Load Diabetes dataset (regression task)\n",
    "diabetes = load_diabetes()\n",
    "X_diabetes = diabetes.data  # features\n",
    "y_diabetes = diabetes.target  # target values\n",
    "\n",
    "# Standardize features for numerical stability\n",
    "scaler = StandardScaler()\n",
    "X_diabetes_scaled = scaler.fit_transform(X_diabetes)\n",
    "\n",
    "# Simulate a linear model: y = dot(x, weights) + bias\n",
    "np.random.seed(42)\n",
    "weights_tabular = np.random.randn(X_diabetes_scaled.shape[1])\n",
    "bias_tabular = np.random.randn()\n",
    "\n",
    "sample_index = 0\n",
    "sample_features = X_diabetes_scaled[sample_index]\n",
    "plaintext_prediction = np.dot(sample_features, weights_tabular) + bias_tabular\n",
    "\n",
    "# Generate Paillier keys with default key length (1024 bits)\n",
    "public_key, private_key = generate_paillier_keys(key_length=1024)\n",
    "\n",
    "# Encrypt the sample features (each element individually)\n",
    "enc_sample = encrypt_vector(sample_features, public_key)\n",
    "\n",
    "# Perform encrypted inference\n",
    "enc_prediction = encrypted_linear_inference(enc_sample, weights_tabular, bias_tabular, public_key)\n",
    "decrypted_prediction = private_key.decrypt(enc_prediction)\n",
    "\n",
    "print(\"=== Diabetes Dataset (Tabular Data) ===\")\n",
    "print(\"Plaintext prediction: {:.4f}\".format(plaintext_prediction))\n",
    "print(\"Encrypted (decrypted) prediction: {:.4f}\".format(decrypted_prediction))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Image Data (MNIST)\n",
    "\n",
    "We load one MNIST image, flatten and normalize it, and run a simple linear model prediction using Paillier encryption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "\n",
      "=== MNIST Image Data ===\n",
      "Plaintext prediction: 2.4648\n",
      "Encrypted (decrypted) prediction: 2.4648\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Select one image from the test set, flatten and normalize (scale pixel values between 0 and 1)\n",
    "sample_image = x_test[0]\n",
    "sample_image_flat = sample_image.flatten() / 255.0\n",
    "\n",
    "# Simulate a linear classifier: y = dot(x, weights) + bias\n",
    "weights_image = np.random.randn(sample_image_flat.shape[0])\n",
    "bias_image = np.random.randn()\n",
    "plaintext_pred_image = np.dot(sample_image_flat, weights_image) + bias_image\n",
    "\n",
    "# Generate new Paillier keys for image data (using default key length)\n",
    "public_key_img, private_key_img = generate_paillier_keys(key_length=1024)\n",
    "\n",
    "# Encrypt the image vector\n",
    "enc_image = encrypt_vector(sample_image_flat, public_key_img)\n",
    "\n",
    "# Encrypted inference\n",
    "enc_pred_image = encrypted_linear_inference(enc_image, weights_image, bias_image, public_key_img)\n",
    "decrypted_pred_image = private_key_img.decrypt(enc_pred_image)\n",
    "\n",
    "print(\"\\n=== MNIST Image Data ===\")\n",
    "print(\"Plaintext prediction: {:.4f}\".format(plaintext_pred_image))\n",
    "print(\"Encrypted (decrypted) prediction: {:.4f}\".format(decrypted_pred_image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Text Data (TF-IDF Representation Proxy)\n",
    "\n",
    "We fetch a small set of newsgroup articles, compute TF-IDF features (limiting to 50 features), and simulate a linear model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 3: Text Data (TF-IDF Representation Proxy)\n",
    "\n",
    "We fetch a small set of newsgroup articles, compute TF-IDF features (limiting to 50 features), and simulate a linear model prediction.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
